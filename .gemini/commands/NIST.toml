description="Ways that the project needs to be compliant as per NIST guidelines SP 800-63B"

Bots in the broader sense—automated programs used for various purposes—are a topic NIST addresses in several contexts, including:

Digital Identity and Authentication: NIST Special Publication (SP) 800-63B, "Digital Identity Guidelines: Authentication and Authenticator Management," contains guidelines that are relevant to bot use, particularly in a security context. While not specifically about bots, the guidelines for authentication, reauthentication, and password requirements are designed to secure systems against unauthorized access, which could be perpetrated by bots.

Robotic Process Automation (RPA): In collaboration with other government agencies like the GSA, NIST has provided recommendations for implementing security controls for RPA bots. This involves aligning bot security with the NIST Risk Management Framework (RMF) and controls from SP 800-53, focusing on things like account management and least privilege for bot accounts.

AI and Chatbots: With the rise of AI and large language models (LLMs), NIST is developing guidance on the security of these tools. For example, NIST Internal Report (IR) 8579, "Developing the NCCoE Chatbot," details the security and technical lessons learned from building a chatbot for internal use. This document highlights a risk-informed approach to managing threats like prompt injection and hallucinations, which are specific vulnerabilities of AI-powered bots.

General Cybersecurity: NIST's comprehensive cybersecurity guidance, such as the Cybersecurity Framework and other Special Publications, provides a foundation for securing any system, including those that use or manage bots. This guidance helps organizations manage risks associated with all types of software and systems, whether they are automated or not.